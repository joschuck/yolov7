# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
train: coco_kpts/train2017.txt  # 118287 images
val: coco_kpts/val2017.txt  # 5000 images
#val: /user/a0132471/Files/bit-bucket/pytorch/jacinto-ai-pytest/data/results/datasets/pytorch_coco_mmdet_img_resize640_val2017_5k_yolov5.txt
test: coco_kpts/test-dev2017.txt  # 20288 of 40670 images, submit to https://competitions.codalab.org/competitions/20794

# number of input channels
ch: 3

# number of classes
nc: 1
names: [ 'person']

# keypoints
nkpt: 17
kpt_names: ["nose", "left_eye", "right_eye", "left_ear", "right_ear", "left_shoulder", "right_shoulder",
            "left_elbow", "right_elbow", "left_wrist", "right_wrist", "left_hip", "right_hip", "left_knee",
            "right_knee", "left_ankle", "right_ankle"]
skeleton: [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],
           [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],
           [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]
flip_index: [0, 2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15]
sigmas: [.26, .25, .25, .35, .35, .79, .79, .72, .72, .62, .62, 1.07, 1.07, .87, .87, .89, .89]